{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data (MNIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 24\n",
    "* Sebastian Häni <haeniseb@students.zhaw.ch>\n",
    "* Raffael Affolter <affolraf@students.zhaw.ch>\n",
    "* Benjamin Mäder <maedeben@students.zhaw.ch>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START YOUR CODE ### \n",
    "data_home = \"/Users/taahase8/deeplearning_data\"\n",
    "### END YOUR CODE ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def load_mnist(data_home):\n",
    "    \"\"\"\n",
    "    Loads the mnist dataset, prints the shape of the dataset and \n",
    "    returns the array with the images, the array with associated labels \n",
    "    and the shape of the images.     \n",
    "    Parameters: \n",
    "    data_home -- Absolute path to the DATA_HOME  \n",
    "    \n",
    "    Returns:\n",
    "    x -- array with images of shape (784,m) where m is the number of images\n",
    "    y -- array with associated labels with shape (1,m) where m is the number of images\n",
    "    shape -- (28,28)\n",
    "    \"\"\"\n",
    "    mnist = fetch_openml(name='mnist_784', version=1, cache=True, data_home=data_home)\n",
    "    x, y = mnist['data'].T, np.array(mnist['target'], dtype='int').T\n",
    "    m = x.shape[1]\n",
    "    y = y.reshape(1,m)\n",
    "    print(\"Loaded MNIST original:\")\n",
    "    print(\"Image Data Shape\" , x.shape)\n",
    "    print(\"Label Data Shape\", y.shape)\n",
    "    return x,y,(28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Class\n",
    "\n",
    "Used to split into train and test, normalize and provide batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Dataset(object):\n",
    "    \n",
    "    def __init__(self, x, y, test_size, random_state=0):\n",
    "        \"\"\"Splits dataset into train and test and normalize the train and test set (min/max normalization).\n",
    "        \n",
    "        Parameters:\n",
    "        x - input features, numpy array of shape(nx,m)\n",
    "        y - labels, numpy array of shape (1,m)\n",
    "        \"\"\"\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x.T, y.T, test_size=test_size, random_state=random_state)\n",
    "        self.xtrain = xtrain.T\n",
    "        self.xtest = xtest.T\n",
    "        self.ytrain = ytrain.T\n",
    "        self.ytest = ytest.T\n",
    "        self._normalize()\n",
    "        \n",
    "        self.nx = self.xtrain.shape[0]\n",
    "        self.mtrain = self.xtrain.shape[1]\n",
    "        self.mtest = self.xtest.shape[1]\n",
    "        print(\"Training Data: x=%s | y=%s, Test Data: x=%s | y=%s\"%(str(self.xtrain.shape), str(self.ytrain.shape), \n",
    "                                                                    str(self.xtest.shape), str(self.ytest.shape)))\n",
    "    \n",
    "    def _normalize(self):\n",
    "        \"\"\"Applies min/max-normalization - min and max values computed from the training set.\n",
    "        Common min and max values for all features are used.\"\"\"\n",
    "        xmax, xmin = np.max(self.xtrain), np.min(self.xtrain)\n",
    "        self.xtrain = 2*(self.xtrain - xmin) / (xmax - xmin) - 1\n",
    "        self.xtest = 2*(self.xtest - xmin) / (xmax - xmin) - 1\n",
    "            \n",
    "    def prepare_batches(self, batchsize=None):\n",
    "        \"\"\"Initialize training set to provide batches of size batchsize. It reshuffles the samples \n",
    "        so that new batches are provided after calling this method. \n",
    "        \"\"\"\n",
    "        if not batchsize:\n",
    "            self.batchsize = self.mtrain\n",
    "        else:\n",
    "            self.batchsize = batchsize\n",
    "        self.mb = int(self.mtrain/self.batchsize)\n",
    "        self.indices = np.arange(self.mtrain)\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.counter = 0\n",
    "      \n",
    "    def number_of_batches(self):\n",
    "        \"\"\"Returns the number of batches. Provides a non-none result only after calling the `prepare_batches`-method.\n",
    "        \n",
    "        Returns:\n",
    "        mb -- number of (complete) batches.  \n",
    "        \"\"\"\n",
    "        return self.mb\n",
    "    \n",
    "    def next_batch(self):\n",
    "        \"\"\"Provides the next batch. If there are no more batches, the `prepare_batches` is called. \n",
    "        \n",
    "        Returns:\n",
    "        xbatch -- numpy array of shape (nx,batchsize)\n",
    "        ybatch -- numpy array of shape (1,batchsize)\n",
    "        \"\"\"\n",
    "        if (self.counter+1) >= self.mb:\n",
    "            self.prepare_batches(self.batchsize)\n",
    "        it = self.indices[self.counter*self.batchsize:(self.counter+1)*self.batchsize]\n",
    "        self.counter += 1\n",
    "        xbatch = self.xtrain[:,it].reshape(self.nx, self.batchsize)\n",
    "        ybatch = self.ytrain[:,it].reshape(1,self.batchsize)\n",
    "        return xbatch, ybatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MNIST original:\n",
      "Image Data Shape (784, 70000)\n",
      "Label Data Shape (1, 70000)\n",
      "Training Data: x=(784, 60000) | y=(1, 60000), Test Data: x=(784, 10000) | y=(1, 10000)\n"
     ]
    }
   ],
   "source": [
    "x, y, shape = load_mnist(data_home)\n",
    "ds = Dataset(x, y, test_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "#### Components\n",
    "\n",
    "In this section, we define the different components of the MLP model, including \n",
    "\n",
    "* _Activation function_ including suitable methods to compute values and derivatives: here, the simoid activation function will be used. \n",
    "* For implementing softmax, a _softmax activation function_ is provided. It just provides the possibility to compute the softmax values, but not the derivatives. The derivatives will be needed for the backpropagation but will be integrated in the code for the softmax layer.  \n",
    "* _Initializer_ for initializing the weights and bias parameters: here, normally distributed initial values will be provided.\n",
    "* _Cost Function_ used for training - including suitable methods for computing the values and derivatives: here, the cross-entropy cost will be used.\n",
    "* _Layer_ : The first core component to be implemented/completed by the students.\n",
    "* _MLP_ : The second core component to be implemented/completed by the students. Allows to configure an arbitrary number of layers into a sequential structure.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class activation_function(object):\n",
    "    \"\"\"\n",
    "    Empty parent implementation of all activation functions. All child implementations should implement \n",
    "    the two methods defined below.\n",
    "    \"\"\"\n",
    "    def compute_value(self, z):\n",
    "        \"\"\"\n",
    "        Computes the value of the activation function element wise for input array z of arbitrary shape. \n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"To be implemented in the child implementation.\")\n",
    "\n",
    "    def compute_derivative(self, z):\n",
    "        \"\"\"\n",
    "        Computes the derivative of the activation function element wise for input array z of arbitrary shape. \n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"To be implemented in the child implementation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sigmoid_activation_function(activation_function):\n",
    "    def compute_value(self, z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def compute_derivative(self, z):\n",
    "        s = self.compute_value(z)\n",
    "        return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmax_activation_function(activation_function):\n",
    "    def compute_value(self, z):\n",
    "        expz = np.exp(z)\n",
    "        norm = np.sum(expz, axis=0)\n",
    "        return expz / norm\n",
    "\n",
    "    def compute_derivative(self, z):\n",
    "        raise NotImplementedError(\n",
    "            \"Computation of the gradient implemented in the Softmax Layer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm_Initializer(object):\n",
    "    def initialize_weights(self, size, mu=0.0, sigma=1.0):\n",
    "        return np.random.normal(size=size, loc=mu, scale=sigma)\n",
    "\n",
    "    def initialize_bias(self, size, mu=0.0, sigma=1.0):\n",
    "        return np.random.normal(size=size, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cost(object):\n",
    "    def compute_value(self, y, prob):\n",
    "        \"\"\"\n",
    "        Computes the value of the cost function for given labels y and predicted probs. \n",
    "        \n",
    "        Arguments:\n",
    "        y -- labels, a numpy array of shape (1,m)\n",
    "        prob -- predicted probabilities for the different classes, a numpy array of shape (ny,m)\n",
    "        \n",
    "        Returns:\n",
    "        cost -- a scalar        \n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"\")\n",
    "\n",
    "    def compute_derivative(self, y, prob):\n",
    "        \"\"\"\n",
    "        Computes the derivative of the cost function w.r.t. predicted probs for given labels y and predicted probs.\n",
    "\n",
    "        Parameters:\n",
    "        y -- labels, a numpy array of shape (1,m)\n",
    "        prob -- predicted probabilities for the different classes, a numpy array of shape (ny,m)\n",
    "        \n",
    "        Returns:\n",
    "        Gradient of cost with respect to the predicted probabilities, a numpy array of shape (ny,m)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(Cost):\n",
    "    def compute_value(self, y, prob):\n",
    "        \"\"\"\n",
    "        Computes the value of the cost function for given labels y and predicted probs.\n",
    "        \n",
    "        Arguments:\n",
    "        y -- labels, a numpy array of shape (1,m)\n",
    "        prob -- predicted probabilities for the different classes, a numpy array of shape (ny,m)\n",
    "        \n",
    "        Returns:\n",
    "        cost -- a scalar\n",
    "        \"\"\"\n",
    "        n, m = prob.shape\n",
    "        assert (np.max(y) <= n)\n",
    "        py = prob[y, np.arange(m)]\n",
    "        J = -np.sum(np.log(py)) / m\n",
    "        return J\n",
    "\n",
    "    def compute_derivative(self, y, prob):\n",
    "        \"\"\"\n",
    "        Computes the derivative of the cost function w.r.t. predicted probs for given labels y and predicted probs.\n",
    "\n",
    "        Parameters:\n",
    "        y -- labels, a numpy array of shape (1,m)\n",
    "        prob -- predicted probabilities for the different classes, a numpy array of shape (ny,m)\n",
    "        \n",
    "        Returns:\n",
    "        Gradient of cost with respect to the predicted probabilities, a numpy array of shape (ny,m)\n",
    "        \"\"\"\n",
    "        n, m = prob.shape\n",
    "        result = np.zeros((n, m), dtype=float)\n",
    "        result[y[0, :], np.arange(m)] = 1.0\n",
    "        result /= prob\n",
    "        return -result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \n",
    "    def __init__(self, layerid, nunits, nunits_prev, activ_func, initializer):\n",
    "        \"\"\"\n",
    "        Instantiates a fully connected layer for an MLP, with given number of input and output activations.\n",
    "        \n",
    "        Arguments:\n",
    "        layerid -- integer id for the layer.\n",
    "        nunits -- number of units in the given layer.\n",
    "        nunits_prev -- number of units in the previous layer (= number of input activations).\n",
    "        activ_func -- activation function to be used (with a `compute_value`- and `compute_derivative`-method).\n",
    "        initializer -- initializer for the weights and the biases.        \n",
    "        \"\"\"\n",
    "        self.layerid = layerid\n",
    "        self.nunits = nunits\n",
    "        self.nunits_prev = nunits_prev\n",
    "        self.initializer = initializer\n",
    "        self.activ_func = activ_func\n",
    "        \n",
    "        self.weights = None # shape (nunits,nunits_prev)\n",
    "        self.bias = None # shape (nunits,1)\n",
    "        self.logits = None # z-values, shape(nunits,m) - will be needed for the backprop part ...\n",
    "        self.activations = None # shape(nunits,m)\n",
    "        self.grad_logits = None # grad w.r.t. z, shape(nunits,m) - will be needed as basis for different gradients\n",
    "        \n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases. It uses Xavier normalisation (to be discussed in \"regularisation\").\n",
    "        \"\"\"\n",
    "        sigmaw = np.sqrt(2.0/(self.nunits+self.nunits_prev)) # suited for sigmoid activation function\n",
    "        sigmab = np.sqrt(1.0/self.nunits)\n",
    "        self.weights = self.initializer.initialize_weights(size=(self.nunits,self.nunits_prev), mu=0.0, sigma=sigmaw)\n",
    "        self.bias = self.initializer.initialize_bias(size=(self.nunits,1), mu=0.0, sigma=sigmab)\n",
    "        \n",
    "    \n",
    "    def propagate(self, activations_prev):\n",
    "        \"\"\"\n",
    "        Computes the activations of the layer given the activations of the previous layer.\n",
    "        Caches the computed logits (z-values) and activations since the values will be needed \n",
    "        when using backpropagation to compute the gradients w.r.t. weigths and biases.\n",
    "\n",
    "        Arguments:\n",
    "        activations_prev -- activations of the previous layer (or input layer). A numpy array of shape \n",
    "        (nunits_prev,m).\n",
    "        \n",
    "        Returns:\n",
    "        activations -- activations of this layer, a numpy array of shape (nunits,m)\n",
    "        \"\"\"\n",
    "        np.testing.assert_equal(activations_prev.shape[0],self.nunits_prev)\n",
    "        ### START YOUR CODE ###\n",
    "        self.logits = np.dot(self.weights, activations_prev) + self.bias\n",
    "        self.activations = self.activ_func.compute_value(self.logits)\n",
    "        ### END YOUR CODE ###\n",
    "        return self.activations\n",
    "\n",
    "    \n",
    "    def backpropagate(self, grad_activations):\n",
    "        \"\"\"\n",
    "        Computes the gradient of the cost w.r.t. to the input activations (activations of the previous \n",
    "        layer a^[l-1]) of the given layer. It also computes the gradient w.r.t. the logits (z-values) of \n",
    "        the given layer. This will be needed as the basis for computing the gradient of the cost w.r.t. \n",
    "        the weights and bias of the given layer. \n",
    "        \n",
    "        The method assumes that the forward propagation (`propagate`) has been invoked for the given mini-batch \n",
    "        so that consistent logit-values (self.logits) and activations (self.activations) are available.  \n",
    "        \n",
    "        Arguments:\n",
    "        grad_activations -- gradient of the cost w.r.t. to the output activations of the given layer (a^[l]). \n",
    "        A numpy array of shape (nunits_prev,m) \n",
    "        \n",
    "        Returns:\n",
    "        grad_activations_prev -- gradient of the cost w.r.t. to the input activations of the given layer.\n",
    "        \"\"\"\n",
    "        nsamples =  self.logits.shape[1]\n",
    "        np.testing.assert_equal(grad_activations.shape,(self.nunits,nsamples))\n",
    "\n",
    "        ### START YOUR CODE ###\n",
    "        # useful for testing the shapes - once self.grad_logits is computed check shape with:\n",
    "        self.grad_logits = self.activ_func.compute_derivative(self.logits) * grad_activations\n",
    "        np.testing.assert_equal(self.grad_logits.shape, (self.nunits, nsamples))\n",
    "\n",
    "        # useful for testing the shapes - once self.grad_activations_prev is computed check shape with:\n",
    "        grad_activations_prev = np.dot(self.weights.T, self.grad_logits)\n",
    "        np.testing.assert_equal(grad_activations_prev.shape, (self.nunits_prev, nsamples))\n",
    "\n",
    "        return grad_activations_prev\n",
    "        ### END YOUR CODE ###\n",
    "        \n",
    "    \n",
    "    def gradient_weights(self, activations_prev):\n",
    "        \"\"\"\n",
    "        Computes the gradient of the cost w.r.t. the weights of the given layer and for the given mini-batch.  \n",
    "\n",
    "        The method assumes that `backpropagate` (and `propagate`) has been invoked for the given mini-batch \n",
    "        so that consistent the gradient w.r.t. the logits is available.  \n",
    "\n",
    "        Arguments:\n",
    "        activations_prev -- activations of the previous layer (or input layer). A numpy array of shape \n",
    "        (nunits_prev,m).\n",
    "        \n",
    "        Returns:\n",
    "        grad_weights -- the gradient w.r.t. to the weights. A numpy array of shape (nunits, nunits_prev).\n",
    "        \"\"\"\n",
    "        ### START YOUR CODE ###\n",
    "        return np.dot(self.grad_logits, activations_prev.T) / activations_prev.shape[1]\n",
    "        ### END YOUR CODE ###\n",
    "    \n",
    "\n",
    "    def gradient_bias(self):\n",
    "        \"\"\"\n",
    "        Computes the gradient of the cost w.r.t. the bias of the given layer and for the given mini-batch.  \n",
    "                \n",
    "        The method assumes that `backpropagate` (and `propagate`) has been invoked for the given mini-batch \n",
    "        so that consistent the gradient w.r.t. the logits is available.  \n",
    "                \n",
    "        Returns:\n",
    "        grad_bias -- the gradient w.r.t. to the bias. A numpy array of shape (nunits, 1).\n",
    "        \"\"\"\n",
    "        ### START YOUR CODE ###\n",
    "        return self.grad_logits.mean()\n",
    "        ### END YOUR CODE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "\n",
    "    def __init__(self, layerid, nunits, nunits_prev, initializer):\n",
    "        \"\"\"\n",
    "        Instantiates a Softmax layer with given number of input activations and normalised scores.\n",
    "        \n",
    "        Arguments:\n",
    "        layerid -- integer id for the layer.\n",
    "        nunits -- number of units in the given layer (=number of classes).\n",
    "        nunits_prev -- number of units in the previous layer (= number of input activations).\n",
    "        initializer -- initializer for the weights and the biases.        \n",
    "        \"\"\"\n",
    "        super().__init__(layerid, nunits, nunits_prev, softmax_activation_function(), initializer)\n",
    "        \n",
    "    def backpropagate(self, grad_activations):\n",
    "        \"\"\"\n",
    "        Computes the gradient of the cost w.r.t. to the input activations (activations of the previous \n",
    "        layer, activations_prev) of the softmax layer. It also computes the gradient w.r.t. the logits (z-values) of \n",
    "        the softmax layer. This will be needed as the basis for computing the gradient of the cost w.r.t. \n",
    "        the weights and bias of the layer. \n",
    "        \n",
    "        The method assumes that the forward propagation (`propagate`) has been invoked for the given mini-batch \n",
    "        so that consistent logit-values (z-logits) and activations (self.activations) are available.  \n",
    "        \n",
    "        Arguments:\n",
    "        grad_activations -- gradient of the cost w.r.t. to the output activations of the given layer. \n",
    "        A numpy array of shape (nunits_prev,m) \n",
    "        \n",
    "        Returns:\n",
    "        grad_activations_prev -- gradient of the cost w.r.t. to the input activations of the given layer.\n",
    "        \"\"\"\n",
    "        ### START YOUR CODE ###\n",
    "        activation_sum = np.sum(self.activations * grad_activations, axis=0)\n",
    "        self.grad_logits = self.activations * grad_activations - activation_sum * self.activations\n",
    "        grad_activations_prev = self.weights.T.dot(self.grad_logits)\n",
    "        return grad_activations_prev\n",
    "        ### END YOUR CODE ###            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    \n",
    "    def __init__(self, units_per_layer, activ_func, initializer, softmax_as_last_layer=True):\n",
    "        \"\"\"\n",
    "        Instantiates a (fully connected) MLP with architecture specified by the list `units_per_layer` \n",
    "        which contains the number of units for the layers (including the input and the output layer).\n",
    "        It instantiates the Layer-objects and uses layerid=0 for the first hidden layer, layerid=1 \n",
    "        for the second, etc.\n",
    "        \n",
    "        Arguments:\n",
    "        units_per_layer -- list with the number of units per layers (including the input and the output layer)\n",
    "        activ_func -- activation function to be used in the different layers except possibly in the output \n",
    "        layer (in case softmax_as_last_layer=True)\n",
    "        initializer -- initializer for the weights and biases of all the layers.\n",
    "        softmax_as_last_layer -- flag to indicate whether the last layer should be a softmax layer.\n",
    "        \"\"\"\n",
    "        self.layers = [] # list of layers (instances of class Layer or Softmax or the like); ordered along the forward path.\n",
    "        self.number_layers = -1 # number of layers (excluding input layer, excluding softmax layer)\n",
    "        self.x = None # input data for one iteration (propagate and backpropagate) \n",
    "\n",
    "        self.number_layers = len(units_per_layer)-1 # input layer not counted as layer\n",
    "        if softmax_as_last_layer:\n",
    "            self.number_layers -= 1\n",
    "        layerid = 0\n",
    "        for i in range(self.number_layers):\n",
    "            layerid += 1\n",
    "            layer = Layer(layerid=layerid, nunits=units_per_layer[i+1], nunits_prev=units_per_layer[i], activ_func=activ_func, initializer=initializer)\n",
    "            self.layers.append(layer)\n",
    "        if softmax_as_last_layer:\n",
    "            layerid += 1\n",
    "            layer = Softmax(layerid, units_per_layer[self.number_layers+1], units_per_layer[self.number_layers], initializer)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Calls the `initialize`-method of the layers which are used to properly initialize the weights and biases. \n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.initialize()\n",
    "    \n",
    "    def propagate(self, x): \n",
    "        \"\"\"\n",
    "        Computes the output of the MLP for given input (by using the propagate-method). By executing this method \n",
    "        on a given input mini-batch, the activations and the logits of all the layers are computed \n",
    "        and cached (consistent with the mini-batch). \n",
    "        \n",
    "        Arguments:\n",
    "        x -- input of shape (n_0,m)\n",
    "        \n",
    "        Returns: \n",
    "        a -- activations of the last layer of shape (n_L,m)\n",
    "        \"\"\"\n",
    "        ### START YOUR CODE ###\n",
    "        self.x = x\n",
    "        a = self.x\n",
    "        for layer in self.layers:\n",
    "            a = layer.propagate(a)\n",
    "        return a\n",
    "        ### END YOUR CODE ###\n",
    "\n",
    "    def backpropagate(self, grady):\n",
    "        \"\"\"\n",
    "        Executes backpropagation for the given MLP (after having executed the `propagate`-method).\n",
    "        It starts with passing in the gradient of the cost w.r.t. the activations of the last layer \n",
    "        (i.e. the input to the cost function) and ends up with the gradient of the cost w.r.t. the \n",
    "        input to the first layer (e.g. input x). Once this method has been run, the gradients w.r.t.\n",
    "        to the logits (z-values) are computed and cached. These will be used to update the weights \n",
    "        and biases in accordance with the gradient descent principle. \n",
    "        \n",
    "        Arguments:\n",
    "        grady -- gradient with respect to the output of the network, i.e. the activations of the last layer\n",
    "        that is input to the cost function. A numpy array of shape (n_L,m)\n",
    "        \n",
    "        Returns:\n",
    "        gradient with respect to the inputs to the network. A numpy array of shape (n_0,m)\n",
    "        \"\"\"\n",
    "        ### START YOUR CODE ###        \n",
    "        grad0 = grady\n",
    "        for layer in reversed(self.layers):\n",
    "            grad0 = layer.backpropagate(grad0)\n",
    "        return grad0\n",
    "        ### END YOUR CODE ###        \n",
    "    \n",
    "    def update_params(self, learning_rate):\n",
    "        \"\"\"\n",
    "        Update the weights and biases of all the layers consistent with the gradient descent principle.\n",
    "        It assumes that the propagate and backpropagate methods have been executed.\n",
    "        \n",
    "        Arguments:\n",
    "        learning_rate -- learning rate to be used in the update rule.   \n",
    "        \"\"\"\n",
    "        ### START YOUR CODE ###\n",
    "        activations = self.x\n",
    "        for layer in self.layers:\n",
    "            gradient_weights = layer.gradient_weights(activations)\n",
    "            gradient_bias = layer.gradient_bias()\n",
    "            learned_weights = learning_rate * gradient_weights\n",
    "            learned_bias = learning_rate * gradient_bias\n",
    "            layer.weights = layer.weights - learned_weights\n",
    "            layer.bias = layer.bias - learned_bias\n",
    "            activations = layer.activations\n",
    "        ### END YOUR CODE ###        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the Implementation of Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x00 = np.array([0.2,0.1,-0.3, 0.2, 0.5,-1.0, 1.0,1.5,-1.0]).reshape(3,3)\n",
    "layersizes = [3,10,20,10,5]\n",
    "np.random.seed(1)\n",
    "mlp = MLP(layersizes, sigmoid_activation_function(), Norm_Initializer(), True)\n",
    "for layerid in range(len(layersizes)-1):\n",
    "    layer = mlp.layers[layerid]\n",
    "    layer.weights = np.ones(shape=(layer.nunits,layer.nunits_prev), dtype='float')*0.1\n",
    "    layer.bias = np.zeros(shape=(layer.nunits,1), dtype='float')\n",
    "mlp.initialize()\n",
    "y00 = mlp.propagate(x00)\n",
    "np.testing.assert_equal(y00.shape, (5,3))\n",
    "y00_expected = np.array([\n",
    "    [0.18559891, 0.18553251, 0.18809197],\n",
    "    [0.28155687, 0.28171852, 0.27895721],\n",
    "    [0.05074394, 0.05071549, 0.05141478],\n",
    "    [0.13742613, 0.13757631, 0.13833757],\n",
    "    [0.34467414, 0.34445717, 0.34319847]])\n",
    "np.testing.assert_array_almost_equal(y00, y00_expected, decimal=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Performance of Forward Propagation\n",
    "\n",
    "Measure the runtimes for propagating all the MNIST training set (60'000 samples) with different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec time for batchsize     1 : 91.013 sec\n",
      "Exec time for batchsize    10 : 29.143 sec\n",
      "Exec time for batchsize   100 :  8.908 sec\n",
      "Exec time for batchsize  1000 :  5.876 sec\n",
      "Exec time for batchsize 10000 :  6.029 sec\n",
      "Exec time for batchsize 60000 :  8.735 sec\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "layersizes = [ds.nx, 1000, 800, 700, 600, 400, 200, 100, 100, 10]\n",
    "mlp = MLP(layersizes, sigmoid_activation_function(), Norm_Initializer(), True)\n",
    "mlp.initialize()\n",
    "batchsizes = [1, 10, 100, 1000, 10000, 60000]\n",
    "runtimes = {}\n",
    "nsamples = ds.mtrain\n",
    "\n",
    "for batchsize in batchsizes:\n",
    "    start = timer()\n",
    "    ds.prepare_batches(batchsize)\n",
    "    for i in range(ds.number_of_batches()):\n",
    "        xx, yy = ds.next_batch()\n",
    "        yypred = mlp.propagate(xx)\n",
    "    end = timer()\n",
    "    runtime = end - start\n",
    "    print(\"Exec time for batchsize %5i : %6.3f sec\" % (batchsize, runtime))\n",
    "    runtimes[batchsize] = runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When batch size=1, we expect to have a slow propagation time as it's not batched. The Dataset class has methods like `next_batch` which will be executed as many times as there are samples and no fancy low level numpy hardware optimization can take place.\n",
    "\n",
    "Why the performance is worse when we surpass a batch size of 1000, is a good question though. The only explanation I can come up with is that the data inside the batch has now reached a volume that does not fit into CPU caches anymore and thus the performance gets worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the Implementation of the Gradient\n",
    "\n",
    "For checking the implementation, compute a numeric approximation of the gradient ('numeric gradient') by using the formula as explained in the class. Compare this with the analytic formulas ('analytic gradient') obtained when implementing backprop (or the derivatives of the cross entropy cost).\n",
    "\n",
    "Actually, do this checking for the cross entropy cost as well as for the MLP model.\n",
    "\n",
    "When choosing delta0~1.0e-8, we expect a difference of the numeric and the analytic gradient of <= 3.0e-7.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1854167203395605e-08\n",
      "0.0\n",
      "1.414096573171264e-07\n"
     ]
    }
   ],
   "source": [
    "# Check Gradient of Cross Entropy Cost\n",
    "\n",
    "ce = CrossEntropy()\n",
    "\n",
    "y = np.array([0, 2]).reshape(1, 2)\n",
    "probs0 = np.array([[0.7, 0.1, 0.2]]).reshape(1, 3).T\n",
    "J0 = ce.compute_value(y, probs0)\n",
    "\n",
    "delta0 = 1.0e-8\n",
    "for i in range(3):\n",
    "    delta = np.zeros((3, 1), dtype='float')\n",
    "    delta[i, 0] = delta0\n",
    "    probs1 = probs0 + delta\n",
    "    J1 = ce.compute_value(y, probs1)\n",
    "    numeric = (J1 - J0) / delta0\n",
    "    analytic = ce.compute_derivative(y, probs0)[i, 0]\n",
    "    d = np.abs(numeric - analytic)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing layer with id 0\n",
      "Testing layer with id 1\n",
      "Testing layer with id 2\n",
      "Testing layer with id 3\n"
     ]
    }
   ],
   "source": [
    "# Check gradient of cost w.r.t. weights and biases of MLP\n",
    "# An output with a discrepancy is provided only if the difference between numeric and analytic gradient \n",
    "# exceeds the accuray of 3.0e-7. Definitely, the difference should not get much larger than this accuracy.\n",
    "\n",
    "accuracy = 3.0e-7\n",
    "\n",
    "layersizes = [100,200,300,100,10]\n",
    "mlp0 = MLP(layersizes, sigmoid_activation_function(), Norm_Initializer(), True)\n",
    "mlp0.initialize()\n",
    "mlp1 = MLP(layersizes, sigmoid_activation_function(), Norm_Initializer(), True)\n",
    "mlp1.initialize()\n",
    "for layerid in range(len(layersizes)-1):\n",
    "    mlp1.layers[layerid].weights = mlp0.layers[layerid].weights.copy()\n",
    "    mlp1.layers[layerid].bias = mlp0.layers[layerid].bias.copy()\n",
    "\n",
    "m = 2\n",
    "x = np.random.uniform(-0.5,0.5,size=(layersizes[0],m))\n",
    "y = np.random.randint(0,3,size=(1,m))\n",
    "probs0 = mlp0.propagate(x)\n",
    "gradJ = ce.compute_derivative(y,probs0)\n",
    "mlp0.backpropagate(gradJ)\n",
    "J0 = ce.compute_value(y,probs0)\n",
    "\n",
    "delta0 = 1.0e-8\n",
    "for layerid in range(len(layersizes)-1):\n",
    "    print(\"Testing layer with id %s\"%(layerid))\n",
    "    if layerid==0:\n",
    "        activations_prev = x\n",
    "    else:\n",
    "        activations_prev = mlp0.layers[layerid-1].activations\n",
    "    for i in range(layersizes[layerid+1]):\n",
    "        for j in range(layersizes[layerid]):\n",
    "            mlp1.layers[layerid].weights[i,j]+=delta0\n",
    "            probs1 = mlp1.propagate(x)\n",
    "            J1 = ce.compute_value(y,probs1)\n",
    "            numeric = (J1-J0)/delta0\n",
    "            analytic = mlp0.layers[layerid].gradient_weights(activations_prev)[i,j]\n",
    "            d = np.abs(numeric-analytic)\n",
    "            if d > accuracy:\n",
    "                print(\"Layer %i (%i,%i)\"%(layerid,i,j), d, numeric, analytic)\n",
    "            mlp1.layers[layerid].weights[i,j]-=delta0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics Class\n",
    "\n",
    "For not littering the optimization loop with code to keep track of the learning results over the epochs we defined a suitable metrics object that keeps all the data (cost function, classification error vs epochs). It also provides utility methods for updating, printing values or plotting the learning curves.\n",
    "\n",
    "It is defined as python class the metrics object then needs to be instantiated from. It means that some small knowledge about object-oriented programming is needed here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Metrics():\n",
    "    \"\"\"\n",
    "    Allows to collect statistics (such as classification error or cost) that are of interest over the course of training\n",
    "    and for creating learning curves that are a useful tool for analyzing the quality of the learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cost):\n",
    "        \"\"\"\n",
    "        Constructor for a metrics object. \n",
    "        Initializes all the statistics to track in form of python lists.\n",
    "        \n",
    "        Parameters:\n",
    "        cost -- cost function to use (a python function)\n",
    "        smooth -- if set to true updates learning curve after each training step and also provides learning curves \n",
    "        smoothed over the epoch  \n",
    "        \"\"\"\n",
    "        self.epochs = []\n",
    "        self.train_costs_last = []\n",
    "        self.test_costs_last = []\n",
    "        self.train_errors_last = []\n",
    "        self.test_errors_last = []\n",
    "\n",
    "        self.cost = cost\n",
    "        self.init_epoch()\n",
    "\n",
    "            \n",
    "    def init_epoch(self):\n",
    "        self.train_costs_epoch = []\n",
    "        self.test_costs_epoch = []\n",
    "        self.train_errors_epoch = []\n",
    "        self.test_errors_epoch = []\n",
    "        \n",
    "        \n",
    "    def update_epoch(self, epoch):\n",
    "        \"\"\"\n",
    "        Computes the average of the metrics over the epoch and adds the result to the per epoch history\n",
    "        \n",
    "        Parameters:\n",
    "        epoch -- the epoch to add to the per epoch cache\n",
    "        \"\"\"\n",
    "        self.epochs.append(epoch)\n",
    "        self.train_costs_last.append(self.train_costs_epoch[-1])\n",
    "        self.test_costs_last.append(self.test_costs_epoch[-1])\n",
    "        self.train_errors_last.append(self.train_errors_epoch[-1])\n",
    "        self.test_errors_last.append(self.test_errors_epoch[-1])\n",
    "        \n",
    "        self.init_epoch()\n",
    "    \n",
    "    def error_rate(self, y, probs):\n",
    "        m = y.shape[1]\n",
    "        ypred = np.argmax(probs, axis=0).reshape(1,m)\n",
    "        rate = np.sum(y != ypred) / m\n",
    "        return rate        \n",
    "        \n",
    "    def update_iteration(self, ypred_train, y_train, ypred_test, y_test):\n",
    "        \"\"\"\n",
    "        Allows to update the statistics to be tracked for a new epoch.\n",
    "        The cost is computed by using the function object passed to the constructor.\n",
    "        \n",
    "        Parameters:\n",
    "        epoch -- Epoch\n",
    "        ypred_train -- predicted values on the training samples, a numpy array of shape (1,m1)\n",
    "        y_train -- ground truth labels associated with the training samples, a numpy array of shape (1,m1)\n",
    "        ypred_test -- predicted values on the test samples, a numpy array of shape (1,m2)\n",
    "        y_test -- ground truth labels associated with the test samples, a numpy array of shape (1,m2)\n",
    "        \"\"\"\n",
    "        Jtrain = self.cost.compute_value(y_train, ypred_train)\n",
    "        Jtest = self.cost.compute_value(y_test, ypred_test)\n",
    "        train_error = self.error_rate(y_train, ypred_train)\n",
    "        test_error = self.error_rate(y_test, ypred_test)\n",
    "\n",
    "        self.train_costs_epoch.append(Jtrain)\n",
    "        self.test_costs_epoch.append(Jtest)\n",
    "        self.train_errors_epoch.append(train_error)\n",
    "        self.test_errors_epoch.append(test_error)\n",
    "        \n",
    "        \n",
    "    def print_latest_errors(self):\n",
    "        print (\"Train/test error after epoch %i: %f, %f\" %(self.epochs[-1], self.train_errors_last[-1], self.test_errors_last[-1]))\n",
    "\n",
    "    def print_latest_costs(self):\n",
    "        print (\"Train/test cost after epoch %i: %f, %f\" %(self.epochs[-1], self.train_costs_last[-1], self.test_costs_last[-1]))\n",
    "\n",
    "    def plot_cost_curves(self, xrange=None, yrange=None, logscale=True):\n",
    "        if logscale:\n",
    "            plt.semilogy(self.epochs, self.train_costs_last, \"b-\", label=\"train\")\n",
    "            plt.semilogy(self.epochs, self.test_costs_last, \"r-\", label=\"test\")\n",
    "        else:\n",
    "            plt.plot(self.epochs, self.train_costs_last, \"b-\", label=\"train\")\n",
    "            plt.plot(self.epochs, self.test_costs_last, \"r-\", label=\"test\")            \n",
    "        plt.ylabel('Cost')\n",
    "        plt.xlabel('Epochs')\n",
    "        if not xrange:\n",
    "            xrange=(0,self.epochs[-1])\n",
    "        if not yrange:\n",
    "            ymin = min(max(1e-5,np.min(self.train_costs_last)),max(1e-5,np.min(self.test_costs_last))) * 0.8\n",
    "            ymax = max(np.max(self.train_costs_last),np.max(self.test_costs_last)) * 1.2\n",
    "            yrange = (ymin,ymax)\n",
    "        plt.axis([xrange[0],xrange[1],yrange[0],yrange[1]])\n",
    "        plt.legend()\n",
    "        plt.show()        \n",
    "    \n",
    "    def plot_error_curves(self, xrange=None, yrange=None, logscale=True):\n",
    "        if logscale:\n",
    "            plt.semilogy(self.epochs, self.train_errors_last, \"b-\", label=\"train\")\n",
    "            plt.semilogy(self.epochs, self.test_errors_last, \"r-\", label=\"test\")\n",
    "        else:\n",
    "            plt.plot(self.epochs, self.train_errors_last, \"b-\", label=\"train\")\n",
    "            plt.plot(self.epochs, self.test_errors_last, \"r-\", label=\"test\")            \n",
    "        plt.ylabel('Errors')\n",
    "        plt.xlabel('Epochs')\n",
    "        if not xrange:\n",
    "            xrange=(0,self.epochs[-1])\n",
    "        if not yrange:\n",
    "            ymin = min(max(1e-5,np.min(self.train_errors_last)),max(1e-5,np.min(self.test_errors_last))) * 0.8\n",
    "            ymax = max(np.max(self.train_errors_last),np.max(self.test_errors_last)) * 1.2\n",
    "            yrange = (ymin,ymax)\n",
    "        plt.axis([xrange[0],xrange[1],yrange[0],yrange[1]])        \n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(mlp, cost, ds, nepochs, learning_rate, batchsize=32, debug=True):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    mlp -- instance of MLP\n",
    "    cost -- instance of cost function to be used.\n",
    "    ds -- instance of Dataset class\n",
    "    nepochs -- number of epochs (sweeps through the training dataset in the optimization loop)\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    batchsize -- batch size, defaults to 32\n",
    "    debug -- if true prints training and test error values after each epoch. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "    metrics -- contain the information about the learning curves\n",
    "    \"\"\" \n",
    "    mlp.initialize()\n",
    "    metrics = Metrics(cost = cost)\n",
    "    ds.prepare_batches(batchsize)\n",
    "    \n",
    "    # compute and set the initial values for the metrics curves\n",
    "    ypred_train = mlp.propagate(ds.xtrain)    \n",
    "    ypred_test = mlp.propagate(ds.xtest)    \n",
    "    metrics.update_iteration(ypred_train, ds.ytrain, ypred_test, ds.ytest)\n",
    "    metrics.update_epoch(0)\n",
    "    \n",
    "    # Loop over the epochs    \n",
    "    for i in range(nepochs):\n",
    "                \n",
    "        ds.prepare_batches(batchsize)\n",
    "        \n",
    "        ### START YOUR CODE ### \n",
    "        # Loop over the batches: \n",
    "        # propagate and then back-propagate the gradient of the cost\n",
    "        # update the parameters by using the gradient of the costs w.r.t. these parameters and the learning rate\n",
    "        # finally update the metrics object\n",
    "\n",
    "        for j in range(ds.number_of_batches()):\n",
    "            xbatch, ybatch = ds.next_batch()\n",
    "            \n",
    "            ypred = mlp.propagate(xbatch)\n",
    "            gradJ = cost.compute_derivative(ybatch, ypred)\n",
    "            grad0 = mlp.backpropagate(gradJ)\n",
    "            mlp.update_params(learning_rate)\n",
    "            \n",
    "        ypred_train = mlp.propagate(ds.xtrain)\n",
    "        ypred_test = mlp.propagate(ds.xtest)\n",
    "        metrics.update_iteration(ypred_train, ds.ytrain, ypred_test, ds.ytest)\n",
    "        metrics.update_epoch(i + 1)\n",
    "        ### END YOUR CODE ### \n",
    "            \n",
    "        if debug:\n",
    "            metrics.print_latest_errors()\n",
    "        \n",
    "    metrics.print_latest_costs()\n",
    "    metrics.print_latest_errors()\n",
    "\n",
    "    return metrics    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Network: Single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test error after epoch 1: 0.132717, 0.140600\n",
      "Train/test error after epoch 2: 0.107817, 0.113200\n",
      "Train/test error after epoch 3: 0.098250, 0.103900\n",
      "Train/test error after epoch 4: 0.092150, 0.098100\n",
      "Train/test error after epoch 5: 0.087450, 0.094400\n",
      "Train/test error after epoch 6: 0.084567, 0.091300\n",
      "Train/test error after epoch 7: 0.080517, 0.086100\n",
      "Train/test error after epoch 8: 0.078067, 0.084800\n",
      "Train/test error after epoch 9: 0.075250, 0.081400\n",
      "Train/test error after epoch 10: 0.072433, 0.079200\n",
      "Train/test error after epoch 11: 0.070300, 0.076100\n",
      "Train/test error after epoch 12: 0.068267, 0.075100\n",
      "Train/test error after epoch 13: 0.066267, 0.071800\n",
      "Train/test error after epoch 14: 0.064550, 0.069800\n",
      "Train/test error after epoch 15: 0.062383, 0.070000\n",
      "Train/test error after epoch 16: 0.059983, 0.066800\n",
      "Train/test error after epoch 17: 0.058883, 0.066300\n",
      "Train/test error after epoch 18: 0.057983, 0.064800\n",
      "Train/test error after epoch 19: 0.055183, 0.062200\n",
      "Train/test error after epoch 20: 0.054033, 0.060900\n",
      "Train/test error after epoch 21: 0.052167, 0.059400\n",
      "Train/test error after epoch 22: 0.051300, 0.058000\n",
      "Train/test error after epoch 23: 0.050733, 0.057100\n",
      "Train/test error after epoch 24: 0.049383, 0.056300\n",
      "Train/test error after epoch 25: 0.047600, 0.056000\n",
      "Train/test error after epoch 26: 0.046700, 0.055100\n",
      "Train/test error after epoch 27: 0.045550, 0.053300\n",
      "Train/test error after epoch 28: 0.045000, 0.053800\n",
      "Train/test error after epoch 29: 0.044500, 0.052100\n",
      "Train/test error after epoch 30: 0.042667, 0.052700\n",
      "Train/test error after epoch 31: 0.041850, 0.051100\n",
      "Train/test error after epoch 32: 0.041300, 0.051700\n",
      "Train/test error after epoch 33: 0.039350, 0.049800\n",
      "Train/test error after epoch 34: 0.038750, 0.048400\n",
      "Train/test error after epoch 35: 0.038083, 0.048700\n",
      "Train/test error after epoch 36: 0.037217, 0.047600\n",
      "Train/test error after epoch 37: 0.036683, 0.047900\n",
      "Train/test error after epoch 38: 0.036167, 0.047100\n",
      "Train/test error after epoch 39: 0.034767, 0.047000\n",
      "Train/test error after epoch 40: 0.034650, 0.046700\n",
      "Train/test error after epoch 41: 0.034467, 0.046100\n",
      "Train/test error after epoch 42: 0.034383, 0.047000\n",
      "Train/test error after epoch 43: 0.033217, 0.045900\n",
      "Train/test error after epoch 44: 0.032567, 0.044600\n",
      "Train/test error after epoch 45: 0.031917, 0.044400\n",
      "Train/test error after epoch 46: 0.031617, 0.044400\n",
      "Train/test error after epoch 47: 0.030633, 0.043300\n",
      "Train/test error after epoch 48: 0.030467, 0.042800\n",
      "Train/test error after epoch 49: 0.030067, 0.042500\n",
      "Train/test error after epoch 50: 0.029700, 0.042800\n",
      "Train/test error after epoch 51: 0.029367, 0.042000\n",
      "Train/test error after epoch 52: 0.028867, 0.041000\n",
      "Train/test error after epoch 53: 0.028883, 0.040800\n",
      "Train/test error after epoch 54: 0.027533, 0.040800\n",
      "Train/test error after epoch 55: 0.027250, 0.040900\n",
      "Train/test error after epoch 56: 0.026983, 0.040200\n",
      "Train/test error after epoch 57: 0.027183, 0.039300\n",
      "Train/test error after epoch 58: 0.026633, 0.038900\n",
      "Train/test error after epoch 59: 0.025700, 0.038900\n",
      "Train/test error after epoch 60: 0.025633, 0.038100\n",
      "Train/test error after epoch 61: 0.024850, 0.038300\n",
      "Train/test error after epoch 62: 0.024450, 0.038200\n",
      "Train/test error after epoch 63: 0.024700, 0.038400\n",
      "Train/test error after epoch 64: 0.023983, 0.037600\n",
      "Train/test error after epoch 65: 0.023650, 0.036700\n",
      "Train/test error after epoch 66: 0.023767, 0.036100\n",
      "Train/test error after epoch 67: 0.023367, 0.036400\n",
      "Train/test error after epoch 68: 0.023667, 0.036800\n",
      "Train/test error after epoch 69: 0.023183, 0.035500\n",
      "Train/test error after epoch 70: 0.022750, 0.036300\n",
      "Train/test error after epoch 71: 0.022033, 0.035600\n",
      "Train/test error after epoch 72: 0.021950, 0.035100\n",
      "Train/test error after epoch 73: 0.021467, 0.035000\n",
      "Train/test error after epoch 74: 0.021300, 0.035100\n",
      "Train/test error after epoch 75: 0.021217, 0.034500\n",
      "Train/test error after epoch 76: 0.021183, 0.034400\n",
      "Train/test error after epoch 77: 0.020600, 0.033500\n",
      "Train/test error after epoch 78: 0.019850, 0.033700\n",
      "Train/test error after epoch 79: 0.020150, 0.033700\n",
      "Train/test error after epoch 80: 0.020117, 0.033600\n",
      "Train/test error after epoch 81: 0.019450, 0.032800\n",
      "Train/test error after epoch 82: 0.019267, 0.032700\n",
      "Train/test error after epoch 83: 0.019300, 0.032500\n",
      "Train/test error after epoch 84: 0.019150, 0.032700\n",
      "Train/test error after epoch 85: 0.018483, 0.032600\n",
      "Train/test error after epoch 86: 0.018317, 0.033100\n",
      "Train/test error after epoch 87: 0.017800, 0.032300\n",
      "Train/test error after epoch 88: 0.017667, 0.032500\n",
      "Train/test error after epoch 89: 0.017517, 0.032600\n",
      "Train/test error after epoch 90: 0.017333, 0.031300\n",
      "Train/test error after epoch 91: 0.017383, 0.031900\n",
      "Train/test error after epoch 92: 0.017217, 0.030600\n",
      "Train/test error after epoch 93: 0.016850, 0.031200\n",
      "Train/test error after epoch 94: 0.016867, 0.030300\n",
      "Train/test error after epoch 95: 0.017100, 0.030700\n",
      "Train/test error after epoch 96: 0.016050, 0.030400\n",
      "Train/test error after epoch 97: 0.016050, 0.031200\n",
      "Train/test error after epoch 98: 0.015717, 0.030300\n",
      "Train/test error after epoch 99: 0.015783, 0.030800\n",
      "Train/test error after epoch 100: 0.015883, 0.030200\n",
      "Train/test cost after epoch 100: 0.060284, 0.099352\n",
      "Train/test error after epoch 100: 0.015883, 0.030200\n",
      "263.55042855500005\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "### START YOUR CODE ###\n",
    "learning_rate = 0.01\n",
    "batchsize = 32\n",
    "nepochs = 100\n",
    "\n",
    "layersizes = [ds.nx, 150, 10]\n",
    "### END YOUR CODE ###\n",
    "\n",
    "mlp = MLP(layersizes, sigmoid_activation_function(), Norm_Initializer(), True)\n",
    "ce = CrossEntropy()\n",
    "\n",
    "start = timer()\n",
    "metrics = optimize(mlp,\n",
    "                   ce,\n",
    "                   ds,\n",
    "                   nepochs,\n",
    "                   learning_rate,\n",
    "                   batchsize=batchsize,\n",
    "                   debug=True)\n",
    "end = timer()\n",
    "lapsetime = end - start\n",
    "print(lapsetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_cost_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test error after epoch 100: 0.015883, 0.030200\n"
     ]
    }
   ],
   "source": [
    "metrics.plot_error_curves(yrange=(0, 0.1), logscale=False)\n",
    "metrics.print_latest_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Network: four hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test error after epoch 1: 0.887733, 0.885900\n",
      "Train/test error after epoch 2: 0.887733, 0.885900\n",
      "Train/test error after epoch 3: 0.887617, 0.885900\n",
      "Train/test error after epoch 4: 0.887733, 0.885900\n",
      "Train/test error after epoch 5: 0.856150, 0.854600\n",
      "Train/test error after epoch 6: 0.806133, 0.799800\n",
      "Train/test error after epoch 7: 0.645733, 0.639800\n",
      "Train/test error after epoch 8: 0.509833, 0.505200\n",
      "Train/test error after epoch 9: 0.436167, 0.433900\n",
      "Train/test error after epoch 10: 0.354283, 0.351900\n",
      "Train/test error after epoch 11: 0.277850, 0.274500\n",
      "Train/test error after epoch 12: 0.226883, 0.226100\n",
      "Train/test error after epoch 13: 0.194650, 0.197500\n",
      "Train/test error after epoch 14: 0.170350, 0.172500\n",
      "Train/test error after epoch 15: 0.151633, 0.156900\n",
      "Train/test error after epoch 16: 0.134700, 0.140700\n",
      "Train/test error after epoch 17: 0.128517, 0.136900\n",
      "Train/test error after epoch 18: 0.114300, 0.122300\n",
      "Train/test error after epoch 19: 0.108700, 0.114400\n",
      "Train/test error after epoch 20: 0.101100, 0.106500\n",
      "Train/test error after epoch 21: 0.094183, 0.100000\n",
      "Train/test error after epoch 22: 0.090367, 0.095700\n",
      "Train/test error after epoch 23: 0.084200, 0.090600\n",
      "Train/test error after epoch 24: 0.082350, 0.088000\n",
      "Train/test error after epoch 25: 0.075900, 0.080600\n",
      "Train/test error after epoch 26: 0.073133, 0.079400\n",
      "Train/test error after epoch 27: 0.068433, 0.073900\n",
      "Train/test error after epoch 28: 0.065217, 0.071600\n",
      "Train/test error after epoch 29: 0.069083, 0.075800\n",
      "Train/test error after epoch 30: 0.058550, 0.067600\n",
      "Train/test error after epoch 31: 0.059350, 0.067500\n",
      "Train/test error after epoch 32: 0.054033, 0.060800\n",
      "Train/test error after epoch 33: 0.051833, 0.061700\n",
      "Train/test error after epoch 34: 0.049383, 0.059200\n",
      "Train/test error after epoch 35: 0.048033, 0.058700\n",
      "Train/test error after epoch 36: 0.044600, 0.055800\n",
      "Train/test error after epoch 37: 0.045150, 0.056200\n",
      "Train/test error after epoch 38: 0.042417, 0.053500\n",
      "Train/test error after epoch 39: 0.041567, 0.053200\n",
      "Train/test error after epoch 40: 0.041217, 0.052500\n",
      "Train/test error after epoch 41: 0.036900, 0.050500\n",
      "Train/test error after epoch 42: 0.037633, 0.049700\n",
      "Train/test error after epoch 43: 0.035833, 0.048000\n",
      "Train/test error after epoch 44: 0.034983, 0.046700\n",
      "Train/test error after epoch 45: 0.033217, 0.046100\n",
      "Train/test error after epoch 46: 0.035533, 0.048300\n",
      "Train/test error after epoch 47: 0.032467, 0.047400\n",
      "Train/test error after epoch 48: 0.030133, 0.044400\n",
      "Train/test error after epoch 49: 0.028883, 0.043900\n",
      "Train/test error after epoch 50: 0.027183, 0.043600\n",
      "Train/test error after epoch 51: 0.026600, 0.041000\n",
      "Train/test error after epoch 52: 0.025533, 0.042700\n",
      "Train/test error after epoch 53: 0.026200, 0.042900\n",
      "Train/test error after epoch 54: 0.024833, 0.041000\n",
      "Train/test error after epoch 55: 0.024050, 0.041200\n",
      "Train/test error after epoch 56: 0.023500, 0.040700\n",
      "Train/test error after epoch 57: 0.021833, 0.039800\n",
      "Train/test error after epoch 58: 0.024317, 0.040000\n",
      "Train/test error after epoch 59: 0.021283, 0.039000\n",
      "Train/test error after epoch 60: 0.021017, 0.039500\n",
      "Train/test error after epoch 61: 0.020583, 0.039000\n",
      "Train/test error after epoch 62: 0.019317, 0.037100\n",
      "Train/test error after epoch 63: 0.021717, 0.039200\n",
      "Train/test error after epoch 64: 0.018417, 0.037100\n",
      "Train/test error after epoch 65: 0.022367, 0.039700\n",
      "Train/test error after epoch 66: 0.017033, 0.037300\n",
      "Train/test error after epoch 67: 0.016483, 0.035900\n",
      "Train/test error after epoch 68: 0.015583, 0.035800\n",
      "Train/test error after epoch 69: 0.015483, 0.035800\n",
      "Train/test error after epoch 70: 0.015283, 0.035300\n",
      "Train/test error after epoch 71: 0.014583, 0.034800\n",
      "Train/test error after epoch 72: 0.015300, 0.034800\n",
      "Train/test error after epoch 73: 0.017217, 0.036700\n",
      "Train/test error after epoch 74: 0.013100, 0.034100\n",
      "Train/test error after epoch 75: 0.015450, 0.035400\n",
      "Train/test error after epoch 76: 0.013817, 0.036100\n",
      "Train/test error after epoch 77: 0.016000, 0.037000\n",
      "Train/test error after epoch 78: 0.012600, 0.035100\n",
      "Train/test error after epoch 79: 0.012017, 0.033700\n",
      "Train/test error after epoch 80: 0.010983, 0.032800\n",
      "Train/test error after epoch 81: 0.010933, 0.032000\n",
      "Train/test error after epoch 82: 0.010417, 0.033500\n",
      "Train/test error after epoch 83: 0.009750, 0.033000\n",
      "Train/test error after epoch 84: 0.009933, 0.033200\n",
      "Train/test error after epoch 85: 0.009383, 0.033400\n",
      "Train/test error after epoch 86: 0.008567, 0.032500\n",
      "Train/test error after epoch 87: 0.008783, 0.031900\n",
      "Train/test error after epoch 88: 0.007767, 0.031000\n",
      "Train/test error after epoch 89: 0.008300, 0.031400\n",
      "Train/test error after epoch 90: 0.007000, 0.031200\n",
      "Train/test error after epoch 91: 0.008767, 0.033200\n",
      "Train/test error after epoch 92: 0.006800, 0.031500\n",
      "Train/test error after epoch 93: 0.006483, 0.032300\n",
      "Train/test error after epoch 94: 0.006883, 0.032700\n",
      "Train/test error after epoch 95: 0.006383, 0.032800\n",
      "Train/test error after epoch 96: 0.006917, 0.033000\n",
      "Train/test error after epoch 97: 0.008067, 0.033100\n",
      "Train/test error after epoch 98: 0.005600, 0.032300\n",
      "Train/test error after epoch 99: 0.004900, 0.030500\n",
      "Train/test error after epoch 100: 0.005083, 0.030000\n",
      "Train/test cost after epoch 100: 0.027850, 0.117015\n",
      "Train/test error after epoch 100: 0.005083, 0.030000\n",
      "599.5926100290001\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "### START YOUR CODE ###\n",
    "learning_rate = 0.01\n",
    "batchsize = 32\n",
    "nepochs = 100\n",
    "\n",
    "layersizes = [ds.nx, 150, 200, 150, 50, 10]\n",
    "### END YOUR CODE ###\n",
    "\n",
    "mlp = MLP(layersizes, sigmoid_activation_function(), Norm_Initializer(), True)\n",
    "ce = CrossEntropy()\n",
    "\n",
    "start = timer()\n",
    "metrics = optimize(mlp,\n",
    "                   ce,\n",
    "                   ds,\n",
    "                   nepochs,\n",
    "                   learning_rate,\n",
    "                   batchsize=batchsize,\n",
    "                   debug=True)\n",
    "end = timer()\n",
    "lapsetime = end - start\n",
    "print(lapsetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_cost_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test error after epoch 100: 0.005083, 0.030000\n"
     ]
    }
   ],
   "source": [
    "metrics.plot_error_curves(yrange=(0, 0.1), logscale=False)\n",
    "metrics.print_latest_errors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
